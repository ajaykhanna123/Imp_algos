{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "150ad925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a852a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_pdf=[\"Clicking either of these icons will display.  A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.SPSCC Student Computing Center__Headers and Footers __1 \\n SPSCC Student Computing Center__Headers and Footers __2\",\n",
    "           \"The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.SPSCC Student Computing Center__Headers and Footers __2\",\n",
    "            \"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.SPSCC Student Computing Center__Headers and Footers __3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "147ca97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_pdf=[\"Clicking either of these icons will display.  A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.SPSCC Student Computing Center__Headers and Footers __1 \\n SPSCC Student Computing Center__Headers and Footers __2\",\n",
    "           \"The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.SPSCC Student Computing Center__Headers and Footers __2\",\n",
    "            \"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.SPSCC Student Computing Center__Headers and Footers __3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7342971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "footers=[\"SPSCC Student Computing Center__Headers and Footers __1\",\n",
    "         \"SPSCC Student Computing Center__Headers and Footers __2\",\n",
    "        \"SPSCC Student Computing Center__Headers and Footers __3\",\n",
    "        \"SPSCC Student Computing Center__Headers and Footers __4\",\n",
    "        \"SPSCC Student Computing Center__Headers and Footers __5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d48c067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clicking either of these icons will display.  A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.SPSCC Student Computing Center__Headers and Footers __1 \\n SPSCC Student Computing Center__Headers and Footers __2',\n",
       " \"The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.SPSCC Student Computing Center__Headers and Footers __2\",\n",
       " \"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.SPSCC Student Computing Center__Headers and Footers __3\"]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207329d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "630e2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_footer_last_line_array(array_pdf,footers):\n",
    "    array_data_lines=[]\n",
    "    for data in array_pdf:\n",
    "        footers_in_pdf=[]\n",
    "        for footer in footers:\n",
    "            if footer in data:\n",
    "                footers_in_pdf.append(footer)\n",
    "        \n",
    "        tokenize_last=sent_tokenize(data)[-1]\n",
    "        if len(footers_in_pdf)!=0:\n",
    "            last_line_of_page=re.sub(\"|\".join(footers_in_pdf),\"\",str(tokenize_last)).strip()\n",
    "            array_data_lines.append([footers_in_pdf,last_line_of_page])\n",
    "        else:\n",
    "            array_data_lines.append([\"\",tokenize_last])\n",
    "    return array_data_lines\n",
    "array_virtual_lines=create_footer_last_line_array(virtual_pdf,footers)\n",
    "array_ods_lines=create_footer_last_line_array(ods_pdf,footers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "97406dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPSCC Student Computing Center__Headers and Footers __1',\n",
       " 'SPSCC Student Computing Center__Headers and Footers __2']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ods_lines[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "471ed039",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(array_virtual_lines)>len(array_ods_lines):\n",
    "    iteration_array1=array_virtual_lines\n",
    "    iteration_array2=array_ods_lines\n",
    "else:\n",
    "    iteration_array1=array_ods_lines\n",
    "    iteration_array2=array_virtual_lines    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7ada1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    WORD = re.compile(r\"\\w+\")\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4180e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_array2=[[[\n",
    "   ''],\n",
    "  'A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.'],\n",
    " [['SPSCC Student Computing Center__Headers and Footers __2'],\n",
    "  'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'],\n",
    " [['SPSCC Student Computing Center__Headers and Footers __3'],\n",
    "  'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b7eb060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_array1=[[['SPSCC Student Computing C'],\n",
    "  'A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how. \\n '],\n",
    " [['SPSCC Student Computing Center__Headers and Footers __2'],\n",
    "  'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'],\n",
    " [['SPSCC Student Computing Center__Headers and Footers __3'],\n",
    "  'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4aa96954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "[''] ['SPSCC Student Computing Center__Headers and Footers __2']\n",
      "Footer mismatch-> page number -> 1\n",
      "1 1\n",
      "['SPSCC Student Computing Center__Headers and Footers __2'] ['SPSCC Student Computing Center__Headers and Footers __3']\n",
      "Footer passed-> page number -> 2\n",
      "2 2\n",
      "Footer passed-> page number -> 3\n",
      "Total iterations for checking footers 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "footer_index_array2=0\n",
    "footer_index_array1=0\n",
    "total_iterations=0\n",
    "#Time complexity of this algorithm is O(n) where n = footer_index_array1\n",
    "while footer_index_array2<len(iteration_array2) and footer_index_array1<len(iteration_array1)-1:\n",
    "    \n",
    "    print(footer_index_array1,footer_index_array2)\n",
    "    print(iteration_array2[footer_index_array2][0],iteration_array1[footer_index_array1+1][0])\n",
    "    if iteration_array2[footer_index_array2][0]==iteration_array1[footer_index_array1][0]:\n",
    "        last_line_array2=text_to_vector(iteration_array2[footer_index_array2][1])\n",
    "        last_line_array1=text_to_vector(iteration_array1[footer_index_array1][1])\n",
    "#         if iteration_array2[footer_index_array2][1]==iteration_array1[footer_index_array1][1]:\n",
    "        if get_cosine(last_line_array2,last_line_array1)>0.90:\n",
    "            print(\"Footer passed->\",\"page number ->\",footer_index_array1+1)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"Page shrink exists for footer ->\",\"page number->\",footer_index_array1+1)\n",
    "    else:\n",
    "        \n",
    "        if iteration_array1[footer_index_array1][0]==[''] and iteration_array2[footer_index_array2][0]==iteration_array1[footer_index_array1+1][0]:\n",
    "            print(\"Page shrink exists for footer ->\",\"page number->\",footer_index_array1+1)\n",
    "            footer_index_array2+=1\n",
    "        else:\n",
    "            print(\"Footer mismatch->\",\"page number ->\",footer_index_array1+1)\n",
    "    \n",
    "    if iteration_array2[footer_index_array2][0]!=iteration_array1[footer_index_array1+1][0]:\n",
    "        \n",
    "        footer_index_array2+=1\n",
    "    footer_index_array1+=1\n",
    "    total_iterations+=1\n",
    "\n",
    "print(footer_index_array1,footer_index_array2)\n",
    "if footer_index_array1<len(iteration_array1) and footer_index_array2<len(iteration_array2):\n",
    "    if iteration_array2[footer_index_array2][0]==iteration_array1[footer_index_array1][0]:\n",
    "        last_line_array2=text_to_vector(iteration_array2[footer_index_array2][1])\n",
    "        last_line_array1=text_to_vector(iteration_array1[footer_index_array1][1])\n",
    "#         if iteration_array2[footer_index_array2][1]==iteration_array1[footer_index_array1][1]:\n",
    "        if get_cosine(last_line_array2,last_line_array1)>0.90:\n",
    "            print(\"Footer passed->\",\"page number ->\",footer_index_array1+1)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"Page shrink exists for footer ->\",\"page number->\",footer_index_array1+1)\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        print(\"Footer mismatch->\",\"page number ->\",footer_index_array1+1)\n",
    "\n",
    "    total_iterations+=1\n",
    "    \n",
    "\n",
    "if footer_index_array1!=footer_index_array2:\n",
    "    print(\"Footer mismatch\",iteration_array1[footer_index_array1][0])\n",
    "print(\"Total iterations for checking footers\",total_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b6b89699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1=\"A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.\"\n",
    "str2=\"A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.\"\n",
    "str1==str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b6ca311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['SPSCC Student Computing Center__Headers and Footers __2'],\n",
       "  'A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how.'],\n",
       " [['SPSCC Student Computing Center__Headers and Footers __2'],\n",
       "  'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'],\n",
       " [['SPSCC Student Computing Center__Headers and Footers __3'],\n",
       "  'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.']]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6d397f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['SPSCC Student Computing C'],\n",
       "  'A dropdown menu with several options.Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how. \\n '],\n",
       " [['SPSCC Student Computing Center__Headers and Footers __2'],\n",
       "  'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'],\n",
       " [['SPSCC Student Computing Center__Headers and Footers __3'],\n",
       "  'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.']]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aacfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e712b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a32ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d95784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f927913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a6799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e611731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503bdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d9a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488f0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
